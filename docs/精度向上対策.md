# CMI競技会 - 精度向上対策

## 現状分析
- **現在のCV Score**: 0.3794 (目標: 0.50)
- **目標LB Score**: 0.60+ (Bronze Medal)
- **問題**: ベースラインモデルの精度が低く、大幅な改善が必要

## 問題点の特定

### 1. モデル性能の問題
- CV Score 0.3794は目標の0.50を大きく下回る
- Binary F1とMacro F1の両方が低い可能性
- 18クラスの不均衡問題への対処不足

### 2. 特徴量エンジニアリングの不足
EDAで推奨された重要な特徴量が未実装の可能性：
- **IMU特徴量**: acc_magnitude, velocity (diff), jerk (diff²)
- **時系列特徴量**: rolling statistics (mean/std/min/max)
- **周波数領域特徴**: FFT spectral features
- **欠損値インジケータ**: thm_5_available, tof_5_available

### 3. データ前処理の課題
- **欠損値処理**: thm_5 (5.79%)とtof_5 (5.24%)の適切な処理が必要
- **正規化**: 参加者ごとの正規化が未実装の可能性
- **ウィンドウサイズ**: 1.41秒の平均シーケンス長に対する最適化不足

### 4. モデルパラメータの未最適化
現在の設定で改善余地あり：
- num_leaves: 63 → より大きな値も試す
- learning_rate: 0.05 → グリッドサーチで最適化
- min_data_in_leaf: 20 → クラス不均衡に対する調整

## 精度向上のための具体的対策

### Phase 1: 基礎的な改善 (即座に実装)

#### 1. 必須特徴量の追加
```python
# IMU magnitude特徴
acc_magnitude = np.sqrt(acc_x**2 + acc_y**2 + acc_z**2)

# 速度・加速度の微分特徴
velocity_x = np.diff(acc_x)
jerk_x = np.diff(velocity_x)

# ローリング統計量
rolling_windows = [5, 10, 20]  # 0.1秒、0.2秒、0.4秒
for window in rolling_windows:
    rolling_mean = df.rolling(window).mean()
    rolling_std = df.rolling(window).std()
```

#### 2. 欠損値の適切な処理
```python
# 欠損インジケータの作成
df['thm_5_available'] = df['thm_5'].notna().astype(int)
df['tof_5_available'] = df['tof_5_v0'].notna().astype(int)

# センサー5の補完
df['thm_5_imputed'] = df['thm_5'].fillna(df[['thm_1', 'thm_2', 'thm_3', 'thm_4']].median(axis=1))
```

#### 3. クラス重みの実装
```python
# クラス不均衡への対処
from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
sample_weights = np.array([class_weights[label] for label in y_train])
```

### Phase 2: 中級レベルの改善 (1-2日で実装)

#### 1. FFT特徴量の追加
```python
# 周波数領域特徴
from scipy.fft import fft
fft_features = {}
freq_bands = [(0, 2), (2, 5), (5, 10), (10, 25)]  # Hz
for band in freq_bands:
    spectral_energy = compute_spectral_energy(signal, band)
    fft_features[f'spectral_energy_{band[0]}_{band[1]}Hz'] = spectral_energy
```

#### 2. ToF次元削減
```python
# PCAによるToFセンサーの次元削減
from sklearn.decomposition import PCA
pca = PCA(n_components=16)
for i in range(1, 6):
    tof_cols = [f'tof_{i}_v{j}' for j in range(64)]
    tof_pca = pca.fit_transform(df[tof_cols])
```

#### 3. ハイパーパラメータの最適化
```python
# Optunaによる自動最適化
params_to_optimize = {
    'num_leaves': (31, 255),
    'learning_rate': (0.01, 0.3),
    'feature_fraction': (0.5, 1.0),
    'bagging_fraction': (0.5, 1.0),
    'min_data_in_leaf': (10, 100),
    'lambda_l1': (0, 10),
    'lambda_l2': (0, 10)
}
```

### Phase 3: 上級レベルの改善 (3-5日で実装)

#### 1. Two-Stage予測戦略
```python
# Stage 1: Binary classification
binary_model = train_binary_classifier(X_train, y_binary)

# Stage 2: Multi-class classification  
multiclass_model = train_multiclass_classifier(X_train[y_binary == 1], y_multiclass[y_binary == 1])
```

#### 2. 時系列拡張 (tsfresh)
```python
from tsfresh import extract_features
from tsfresh.feature_extraction import ComprehensiveFCParameters

settings = ComprehensiveFCParameters()
extracted_features = extract_features(
    df_sequences,
    column_id='series_id',
    column_sort='timestamp',
    default_fc_parameters=settings
)
```

#### 3. アンサンブル準備
- LightGBM + XGBoost + CatBoost
- 1D CNN for raw sensor data
- Weighted average based on CV scores

## 実装優先順位

### 今すぐ実装すべき項目 (CV 0.38 → 0.45)
1. **acc_magnitude特徴の追加**
2. **欠損値インジケータの作成**
3. **クラス重みの適用**
4. **ローリング統計量 (5, 10, 20 timesteps)**

### 今日中に実装 (CV 0.45 → 0.50)
1. **velocity/jerk特徴の追加**
2. **参加者ごとの正規化**
3. **基本的なFFT特徴 (4バンド)**
4. **ハイパーパラメータの調整**

### 今週中に実装 (CV 0.50 → 0.57)
1. **tsfresh統合**
2. **ToF PCA次元削減**
3. **Two-stage予測**
4. **1D CNNの追加**

## 期待される改善効果

| 施策 | 期待されるCV改善 | 実装難易度 | 優先度 |
|-----|----------------|----------|--------|
| acc_magnitude + 基本特徴 | +0.05-0.07 | 低 | 最高 |
| 欠損値処理改善 | +0.02-0.03 | 低 | 高 |
| クラス重み適用 | +0.03-0.05 | 低 | 高 |
| FFT特徴追加 | +0.03-0.05 | 中 | 高 |
| tsfresh統合 | +0.04-0.06 | 高 | 中 |
| ハイパーパラメータ最適化 | +0.02-0.04 | 中 | 高 |
| Two-stage予測 | +0.03-0.05 | 中 | 中 |

## 実装コマンド

```bash
# 1. データ処理パイプラインの再実行
make bronze  # 欠損値インジケータ追加
make silver  # 新特徴量の実装
make gold    # ML-ready preparation

# 2. モデルの再トレーニング
make train-lgb  # 改善されたLightGBM

# 3. 評価と分析
make evaluate  # 改善効果の確認
make feature-importance  # 特徴量重要度分析

# 4. 次のステップ
make train-cnn  # Deep Learningアプローチ
make ensemble   # モデルアンサンブル
```

## モニタリング指標

改善の進捗を追跡するため、以下を確認：
1. **Binary F1**: 0.65以上を目指す
2. **Macro F1**: 0.55以上を目指す  
3. **Combined Score**: 0.60以上でBronze Medal圏内
4. **CV-LB Gap**: 0.02以内に抑える

## 注意事項

- **GroupKFold必須**: participant_idでの分割を厳守
- **メモリ管理**: tsfreshは大量メモリを使用するため、chunk処理
- **段階的実装**: 基礎的な改善から始めて、効果を確認しながら進める
- **実験記録**: 各改善の効果を記録し、組み合わせを最適化

## まとめ

現在のCV 0.3794から目標の0.60+への改善は大きな挑戦ですが、以下の順序で実装することで達成可能：

1. **基礎改善** (CV 0.38 → 0.45): 必須特徴量の追加
2. **中級改善** (CV 0.45 → 0.52): FFT・最適化
3. **上級改善** (CV 0.52 → 0.60+): tsfresh・アンサンブル

最も重要なのは、**EDAで特定された重要特徴量を確実に実装すること**です。